# 📊 Polynomial & Multi-feature Linear Regression from Scratch

This project demonstrates **Polynomial Regression** and **Multi-feature Linear Regression** implemented from scratch in Python, as well as using **Scikit-Learn**.  
It explores how polynomial features can model non-linear data and how multiple features can be handled using gradient descent.

---

## 🧠 What I Learned

- Expanding features for Polynomial Regression  
- The role of feature scaling in gradient descent  
- Implementing gradient descent for multiple features  
- Visualizing polynomial curves vs. linear fits  
- Comparing from-scratch implementations with Scikit-Learn  

---

## ⚙️ How It Works

1. **Data Preparation** – Load and preprocess data (scaling, polynomial feature creation)  
2. **Model Initialization** – Set initial weights and bias  
3. **Cost Function** – Mean Squared Error (MSE)  
4. **Gradient Descent** – Update weights to minimize cost  
5. **Polynomial Feature Transformation** – Generate higher-order terms  
6. **Visualization** – Compare predicted curves to original data  

---

## 📌 How to Run

```bash
# Clone this repo
git clone https://github.com/VaibhavKhangale/Machine-Learning.git

# Polynomial Regression
cd Machine-Learning/Polynomial Regression

# Open in Jupterlab
jupyter lab FILENAME.ipynb

