# ğŸ“ˆ Logistic Regression from Scratch

This project demonstrates how **Logistic Regression** works under the hood by implementing it from scratch in Python using only basic libraries like NumPy and Matplotlib, as well as using Scikit-Learn for comparison.  
It covers binary classification using the sigmoid activation function and gradient descent optimization.

---

## ğŸ§  What I Learned

- The mathematics behind logistic regression  
- Sigmoid (logistic) function and its role in classification  
- Binary cross-entropy loss function  
- Gradient Descent for classification tasks  
- Visualizing decision boundaries  

---

## âš™ï¸ How It Works

1. **Initialize Parameters** â€“ Set initial weights and bias  
2. **Sigmoid Function** â€“ Convert linear predictions to probabilities  
3. **Loss Function** â€“ Binary Cross-Entropy (Log Loss)  
4. **Gradient Descent** â€“ Update weights to minimize loss  
5. **Prediction** â€“ Classify samples based on probability thresholds  
6. **Visualization** â€“ Plot decision boundaries and loss curves  

---

## ğŸ“Œ How to Run

```bash
# Clone this repo
git clone https://github.com/VaibhavKhangale/Machine-Learning.git

# Navigate to this project
cd Machine-Learning/Logistic Regression

# Open the notebook
jupyter notebook FILENAME.ipynb
```

---

## Notes

![intro](../media/IMG_20250810_000725.jpg)
![more](../media/IMG_20250810_000647.jpg)
